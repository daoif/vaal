# VAAL 执行任务引导

本文档用于引导 AI 帮助用户执行任务。

---

## 触发方式

当用户说以下话时，表示需要执行任务：
- "帮我执行任务"
- "开始执行"
- "运行任务"

---

## 阶段一：检查准备

### 1.1 检查必要文件

确认以下文件存在：
- `.vaal/_workspace/exec/tasks.md` - 任务列表
- `.vaal/_workspace/exec/config.json` - 配置文件

如果不存在，提示用户：
- tasks.md 不存在：需要先拆分任务，对我说"帮我拆分任务"
- config.json 不存在：需要先初始化，对我说"帮我初始化 VAAL"

### 1.2 确认任务列表

读取 tasks.md，向用户展示：
- 待完成任务数量
- 已完成任务数量
- 第一个待执行的任务

---

## 阶段二：环境预检

> **本质**：预检不是跑一个检查脚本，而是 AI 理解配置意图后，主动确保实际环境能支撑任务执行。
>
> **原则**：能自动解决的问题自动解决，需要决策的问题询问用户，阻塞问题不能跳过。

### 2.1 理解配置意图

读取 `config.json`，从中理解用户对这个项目的期望：

| 配置项 | 意图 |
|--------|------|
| `git.autoCommit: true` | 用户希望每个任务完成后自动提交，这意味着必须有可用的 git 仓库 |
| `validation.required` 包含 `test` | 用户希望每个任务完成后跑测试，这意味着测试命令必须能真正执行 |
| `validation.required` 包含 `lint` | 用户希望每个任务完成后跑 lint，这意味着 lint 命令必须能真正执行 |
| `_probe.techStack` | 探测到的技术栈，用于判断项目结构是否就绪 |

**这一步的目的是理解"用户期望的工作方式"，后续检查都是在验证环境是否支持这个工作方式。**

### 2.2 Git 环境检查

**触发条件**：`git.autoCommit: true`

**检查逻辑**：

```
配置要求自动提交
    │
    ├─ 当前是 git 仓库？
    │   ├─ 是 → 检查工作区是否干净，有未提交的更改则提醒用户
    │   └─ 否 → 需要初始化
    │
    └─ 需要初始化时，询问用户：
        ├─ 问题1：是否初始化 git 仓库？
        │   ├─ 是 → 执行 git init
        │   └─ 否 → 关闭 autoCommit（修改 config.json）
        │
        ├─ 问题2（如果初始化）：.vaal 目录如何处理？
        │   ├─ A) 删除 .vaal 内部的 .git，将 .vaal 纳入项目 git 管理
        │   ├─ B) 保留 .vaal 内部的 .git，将 .vaal 排除在项目 git 之外
        │   └─ 用户选择后，执行对应操作（删除内部.git / 添加.gitignore）
        │
        └─ 问题3（如果选择 A 纳入管理）：_workspace 目录是否也纳入？
            │
            │  _workspace 包含任务列表、执行进度、配置等运行数据。
            │
            ├─ A) 纳入 git 管理
            │   ├─ 优点：云端同步，换设备不丢数据；多人协作进度一致
            │   └─ 适合：团队协作、需要版本追溯任务状态的场景
            │
            ├─ B) 排除在 git 之外
            │   ├─ 优点：仓库更干净，不提交临时状态
            │   └─ 适合：个人项目、不关心任务状态同步的场景
            │
            └─ 用户选择后，在 .gitignore 中相应处理
```

**执行动作**：
- 初始化 git 时，创建合理的 `.gitignore`（排除 node_modules、.env 等常见项）
- 根据用户选择处理 `.vaal` 目录和 `_workspace` 目录
- 完成后创建初始提交（如果用户同意）

### 2.3 项目结构检查

**触发条件**：始终执行

**检查逻辑**：

1. **读取任务列表**，识别任务的起点：
   - 任务中是否包含"初始化项目"、"创建项目结构"、"搭建骨架"等任务？
   - 如果有，说明项目结构会在任务执行中创建，不需要提前准备

2. **检查当前项目状态**，根据技术栈判断：
   - Node.js 项目 → 是否有 `package.json`？
   - Python 项目 → 是否有 `requirements.txt` 或 `pyproject.toml`？
   - 其他技术栈 → 根据实际情况判断

3. **判断是否存在"结构缺失"问题**：
   - 任务列表不包含初始化任务，但项目结构不存在 → 这是问题
   - 任务列表包含初始化任务，项目结构不存在 → 这是预期的，不是问题

**如果存在问题，询问用户**：
- "任务列表中没有初始化步骤，但项目结构（如 package.json）不存在。需要我先帮你创建项目结构吗？"

### 2.4 验证命令检查

**触发条件**：`validation.required` 不为空

**检查逻辑**：

验证命令必须能"真正执行"，而不是"静默跳过"。

1. **分析验证命令的依赖**：
   - `npm run test` → 依赖 `package.json` 存在且定义了 `test` 脚本
   - `npm test --if-present` → 如果脚本不存在会静默跳过，这不是真正的验证
   - `pytest` → 依赖 Python 环境和 pytest 安装

2. **检查依赖是否满足**：
   - 如果依赖的文件不存在（如 package.json），但任务列表中会创建 → 可以接受，验证会在项目结构就绪后生效
   - 如果依赖的文件不存在，任务列表中也不会创建 → 这是问题

3. **检查命令是否会"假通过"**：
   - 使用了 `--if-present` 这类参数，且当前脚本不存在 → 验证形同虚设

**如果存在问题，询问用户**：
- "验证命令 `npm run test` 依赖的 test 脚本不存在，且任务列表中没有创建测试的任务。你希望：A) 先跳过验证，后续手动添加测试  B) 现在告诉我测试框架，我帮你配置  C) 其他"

### 2.5 预检总结与确认

完成所有检查后，向用户汇报预检结果：

**格式**：

```
预检完成。

✓ 已解决：
  - xxx

⚠ 需要关注：
  - xxx

准备就绪，是否开始执行？
```

**如果有未解决的阻塞问题**：
- 必须询问用户如何处理
- 不要假设用户的意图
- 不要跳过阻塞问题继续执行

**确认后进入阶段三。**

---

## 阶段三：执行任务

### 3.1 输出执行命令

> ⚠️ **重要**：不要自己执行这个命令，输出给用户让他们在终端执行。
> 
> 因为执行过程需要多次调用 AI CLI，耗时较长，不适合在对话中等待。

```
准备就绪。请在终端执行以下命令开始执行任务：

node .vaal/exec/scripts/run.js

执行完成后回来告诉我，我帮你审查结果。
```

---

## 阶段四：审查结果

当用户说"执行完了"或"执行完成了"时，进入审查阶段。

### 4.1 读取进度

读取 `.vaal/_workspace/exec/progress.txt`，向用户展示：
- 已完成的任务列表
- 每个任务的执行时间
- 是否有失败的任务

### 4.2 处理失败情况

如果有任务失败：
- 读取失败任务的错误信息
- 帮助用户分析原因
- 可以手动修复后重新执行

### 4.3 后续步骤

全部完成后，提示用户：

```
所有任务已完成。建议你：
1. 审查生成的代码
2. 运行测试确认功能正常
3. 如发现问题，对我说"帮我添加修复任务"
```

---

## 配置参考

`config.json` 关键配置项：

| 配置项 | 说明 |
|--------|------|
| `slots.execute` | AI 执行槽位脚本（`exec/slots/codex.js` / `exec/slots/claude.js` / 自定义） |
| `validation.test` | 测试命令 |
| `validation.lint` | Lint 命令 |
| `git.autoCommit` | 是否自动提交 |

详细配置说明见 [CONFIG.schema.md](./CONFIG.schema.md)。

---

## 注意事项

1. **不要自己执行命令** - 执行过程耗时长，让用户在终端执行
2. **关注失败任务** - 帮助用户理解失败原因
3. **引导代码审查** - 执行完成后提醒用户审查代码
